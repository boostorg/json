[/
    Copyright (c) 2019 Vinnie Falco (vinnie.falco@gmail.com)

    Distributed under the Boost Software License, Version 1.0. (See accompanying
    file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)

    Official repository: https://github.com/cppalliance/json
]

[section Benchmarks]

In this section we compare the performance of Boost.JSON against the other
two important libraries of interest, RapidJson which is known for its
considerable performance and nlohmann which underperforms but is
feature-rich. The bench program measures the throughput of serialization
and parsing for the various JSON files located in the data directory. It
tests these implementations:

[table Implementations
[
    [Name]
    [Description]
][
    [[*boost(pool)]]
    [
        Parses the input using a __monotonic_resource__, which is optimized
        for parsing but not subsequent modification.
        The __parser__ object is reused between
        trials, allowing temporary memory allocated by the
        implementation to persist and improve performance.
        
    ]
][
    [[*boost]]
    [
        Parses the input using the default memory resource, which
        uses global operator `new` and `delete`, and is designed
        for general use including mutation of the document
        after it is parsed.
        The __parser__ object is reused between
        trials, allowing temporary memory allocated by the
        implementation to persist and improve performance.
    ]
][
    [[*rapidjson(pool)]]
    [
        Parses the input using an instance of
        [@https://rapidjson.org/classrapidjson_1_1_memory_pool_allocator.html `MemoryPoolAllocator`],
        which is optimized for parsing but not subsequent modification.
        The
        [@https://rapidjson.org/classrapidjson_1_1_generic_document.html `Document`]
        object holding temporary memory is not reused between trials, otherwise
        memory consumption grows without bounds and invalidates the benchmark.
    ]
][
    [[*rapidjson]]
    [
        Parses the input using an instance of
        [@https://rapidjson.org/classrapidjson_1_1_crt_allocator.html `CrtAllocator`],
        which uses global operators `new` and `delete`, and is designed
        for general use including mutation of the document after it is parsed.
        [@https://rapidjson.org/classrapidjson_1_1_generic_document.html `Document`]
        object holding temporary memory is not reused between trials, otherwise
        memory consumption grows without bounds and invalidates the benchmark.
    ]
][
    [[*nlohmann]]
    [
        Parses the input using the static member function
        [@https://nlohmann.github.io/json/classnlohmann_1_1basic__json_ab330c13ba254ea41fbc1c52c5c610f45.html `json::parse`],
        which uses the default `std` allocator, and is designed for general
        use including mutation of the document after it is parsed.
        This library does not provide an interface to reuse temporary
        storage used during parsing or serialization.
    ]
]
]

[heading Methodology]

The input files are all loaded first. Then each configuration is run for
a sufficient number of trials to last at least 5 seconds. The elapsed time,
number of invocations (of parse or serialize), and bytes transferred are
emitted as a sample along with a calculation of through put expressed in
megabytes per second. Several samples (currently six) are generated for
each configuration. All but the median three samples are discarded, with
the remaining samples averaged to produce a single number which is reported
as the benchmark result.

The input files, available in the bench/data directory, are laid out thusly:

[table Input Files
[
    [Name]
    [Size]
    [Description]
][
    [[link json.benchmarks.parse_array_json [*array.json]]]
    [667KB]
    [
        A single array with random values and words.
    ]
][
    [[link json.benchmarks.parse_canada_json [*canada.json]]]
    [2.14MB]
    [
        The largest file, containing a huge number of 2-element
        arrays holding floating-point coordinate pairs.
    ]
][
    [[link json.benchmarks.parse_citm_catalog_json [*citm_catalog.json]]]
    [1.69MB]
    [
        A large JSON with a variety of nesting, types, and lengths.
    ]
][
    [[link json.benchmarks.parse_integers_32_json [*integers-32.json]]]
    [1,353KB]
    [
        One array with random 32-bit integers.
    ]
][
    [[link json.benchmarks.parse_integers_64_json [*integers-64.json]]]
    [596KB]
    [
        One array with random 64-bit integers.
    ]
][
    [[link json.benchmarks.parse_random_json [*random.json]]]
    [2,244 bytes]
    [
        Holds a randomly generated JSON with assorted types.
    ]
][
    [[link json.benchmarks.parse_small_json [*small.json]]]
    [603 bytes]
    [
        Containing a few nested objects with strings.
    ]
][
    [[link json.benchmarks.parse_strings_json [*strings.json]]]
    [992KB]
    [
        Contains a single array with random long strings.
    ]
][
    [[link json.benchmarks.parse_twitter_json [*twitter.json]]]
    [631KB]
    [
        An export of data from Twitter's API.
    ]
]
]

Hardware used for testing: [*Intel(R) Core(TM) i7-6950X CPU @ 3.00GHz],
Windows 10, 64GB RAM.

Thanks to SSE2 optimized string processing algorithms from Peter Dimov,
Boost.JSON significantly outperforms all other libraries for parsing
and serializing unescaped strings:

[heading Parse strings.json]
[$json/images/parse-strings.png [width 668px] [height 712px]]

[heading Serialize strings.json]
[$json/images/serialize-strings.png [width 668px] [height 712px]]

[heading Parse integers-32.json]
[$json/images/parse-integers-32.png [width 668px] [height 712px]]

[heading Serialize integers-32.json]
[$json/images/serialize-integers-32.png [width 668px] [height 712px]]

[heading Parse integers-64.json]
[$json/images/parse-integers-64.png [width 668px] [height 712px]]

[heading Serialize integers-64.json]
[$json/images/serialize-integers-64.png [width 668px] [height 712px]]

[heading Parse small.json]
[$json/images/parse-small.png [width 668px] [height 712px]]

[heading Serialize small.json]
[$json/images/serialize-small.png [width 668px] [height 712px]]

[heading Parse array.json]
[$json/images/parse-array.png [width 668px] [height 712px]]

[heading Serialize array.json]
[$json/images/serialize-array.png [width 668px] [height 712px]]

[heading Parse random.json]
[$json/images/parse-random.png [width 668px] [height 712px]]

[heading Serialize random.json]
[$json/images/serialize-random.png [width 668px] [height 712px]]

[heading Parse twitter.json]
[$json/images/parse-twitter.png [width 668px] [height 712px]]

[heading Serialize twitter.json]
[$json/images/serialize-twitter.png [width 668px] [height 712px]]

[heading Parse citm_catalog.json]
[$json/images/parse-citm-catalog.png [width 668px] [height 712px]]

[heading Serialize citm_catalog.json]
[$json/images/serialize-citm-catalog.png [width 668px] [height 712px]]

[heading Parse canada.json]
[$json/images/parse-canada.png [width 668px] [height 712px]]

[heading Serialize canada.json]
[$json/images/serialize-canada.png [width 668px] [height 712px]]

[/-----------------------------------------------------------------------------]

[endsect]
